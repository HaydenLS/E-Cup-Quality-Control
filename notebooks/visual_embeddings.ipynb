{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b475d7fa",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align: center;\"><b>Работа с изображениями.</b></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69131653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2411a15",
   "metadata": {},
   "source": [
    "# Загрузка данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbca72f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к папке с датасетом\n",
    "DATA_DIR = Path(\"C:/Users/vds/Work/Programming Stuff/ecup/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebe3bea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка\n",
    "df_train = pd.read_csv(DATA_DIR / \"train.csv\", index_col='id')\n",
    "df_test = pd.read_csv(DATA_DIR / \"test_full.csv\", index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c09b72f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем скрипт для работы с данными\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from scripts import data_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c8242bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Обрабатываем и получаем данные\n",
    "df_train_num, df_train_text = data_preprocess.clean_data(df_train)\n",
    "df_test_num, df_test_text = data_preprocess.clean_data(df_test, type='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8d32a0",
   "metadata": {},
   "source": [
    "# Работа с изображениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad4b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к папке с картинками\n",
    "DATA_DIR = Path(\"C:/Users/vds/Work/Programming Stuff/ecup/data/images\")\n",
    "TRAIN_DIR = Path(DATA_DIR / \"train\")\n",
    "TEST_DIR = Path(DATA_DIR / \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f84e1",
   "metadata": {},
   "source": [
    "## 1) Создание эмбеддингов изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bf41d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resolution</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>description</th>\n",
       "      <th>name_rus</th>\n",
       "      <th>CommercialTypeName4</th>\n",
       "      <th>rating_1_count</th>\n",
       "      <th>rating_2_count</th>\n",
       "      <th>rating_3_count</th>\n",
       "      <th>rating_4_count</th>\n",
       "      <th>rating_5_count</th>\n",
       "      <th>...</th>\n",
       "      <th>ExemplarReturnedCountTotal30</th>\n",
       "      <th>ExemplarReturnedCountTotal90</th>\n",
       "      <th>ExemplarReturnedValueTotal7</th>\n",
       "      <th>ExemplarReturnedValueTotal30</th>\n",
       "      <th>ExemplarReturnedValueTotal90</th>\n",
       "      <th>ItemVarietyCount</th>\n",
       "      <th>ItemAvailableCount</th>\n",
       "      <th>seller_time_alive</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>SellerID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6863</th>\n",
       "      <td>0</td>\n",
       "      <td>Levsha kaluga</td>\n",
       "      <td>&lt;p&gt;Мы используем только НОВЫЕ комплектующие пр...</td>\n",
       "      <td>Levsha kaluga Системный блок Игровой компьютер...</td>\n",
       "      <td>Настольный компьютер</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>366.0</td>\n",
       "      <td>366.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>3490</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      resolution     brand_name  \\\n",
       "id                                \n",
       "6863           0  Levsha kaluga   \n",
       "\n",
       "                                            description  \\\n",
       "id                                                        \n",
       "6863  <p>Мы используем только НОВЫЕ комплектующие пр...   \n",
       "\n",
       "                                               name_rus   CommercialTypeName4  \\\n",
       "id                                                                              \n",
       "6863  Levsha kaluga Системный блок Игровой компьютер...  Настольный компьютер   \n",
       "\n",
       "      rating_1_count  rating_2_count  rating_3_count  rating_4_count  \\\n",
       "id                                                                     \n",
       "6863             NaN             NaN             NaN             NaN   \n",
       "\n",
       "      rating_5_count  ...  ExemplarReturnedCountTotal30  \\\n",
       "id                    ...                                 \n",
       "6863             NaN  ...                           NaN   \n",
       "\n",
       "      ExemplarReturnedCountTotal90  ExemplarReturnedValueTotal7  \\\n",
       "id                                                                \n",
       "6863                           NaN                          NaN   \n",
       "\n",
       "      ExemplarReturnedValueTotal30  ExemplarReturnedValueTotal90  \\\n",
       "id                                                                 \n",
       "6863                           NaN                           NaN   \n",
       "\n",
       "      ItemVarietyCount  ItemAvailableCount  seller_time_alive  ItemID  \\\n",
       "id                                                                      \n",
       "6863             366.0               366.0              117.0    3490   \n",
       "\n",
       "      SellerID  \n",
       "id              \n",
       "6863       442  \n",
       "\n",
       "[1 rows x 44 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['ItemID'] == 3490]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "326cad12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "\n",
    "# Загружаем предобученный CLIP\n",
    "model = SentenceTransformer(\"clip-ViT-B-32\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35858be8",
   "metadata": {},
   "source": [
    "Функция: получение эмбеддингов картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fdddc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_image_embeddings(df, img_dir, batch_size=32):\n",
    "    embeddings = []\n",
    "    ids = []\n",
    "\n",
    "    img_paths = [img_dir / f\"{img_id}.png\" for img_id in df[\"ItemID\"]]\n",
    "\n",
    "    for i in tqdm(range(0, len(img_paths), batch_size)):\n",
    "        batch_paths = img_paths[i : i + batch_size]\n",
    "        batch_imgs = []\n",
    "\n",
    "        for path in batch_paths:\n",
    "            try:\n",
    "                img = Image.open(path).convert(\"RGB\")\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при открытии {path}: {e}\")\n",
    "                # если картинки нет или битая, добавим \"пустышку\"\n",
    "                img = Image.new(\"RGB\", (224, 224), (255, 255, 255))\n",
    "            batch_imgs.append(img)\n",
    "\n",
    "        # получаем эмбеддинги\n",
    "        batch_emb = model.encode(batch_imgs, batch_size=batch_size, convert_to_numpy=True, show_progress_bar=False)\n",
    "        embeddings.append(batch_emb)\n",
    "\n",
    "        ids.extend(df.index[i : i + batch_size])\n",
    "\n",
    "    embeddings = np.vstack(embeddings)\n",
    "\n",
    "    return pd.DataFrame(embeddings, index=ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e63a1d",
   "metadata": {},
   "source": [
    "Генерация эмбеддингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66561bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_emb = compute_image_embeddings(df_train, TRAIN_DIR, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acd12795",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 53/981 [01:11<22:59,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\185232.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\185232.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 94/981 [02:13<20:15,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\167026.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\167026.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 115/981 [02:45<20:12,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\62051.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\62051.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 129/981 [03:06<22:45,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\27985.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\27985.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 135/981 [03:14<18:05,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\216973.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\216973.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 139/981 [03:19<18:48,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\186431.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\186431.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 173/981 [04:06<17:59,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\57460.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\57460.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 212/981 [05:02<21:47,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\196506.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\196506.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 227/981 [05:23<18:03,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\181940.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\181940.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 230/981 [05:27<17:47,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\87768.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\87768.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 261/981 [06:11<16:29,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\85189.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\85189.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 268/981 [06:21<17:10,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\66049.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\66049.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 301/981 [07:07<16:33,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\60780.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\60780.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 414/981 [09:46<17:03,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\103474.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\103474.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 416/981 [09:48<15:09,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\85508.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\85508.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 420/981 [09:54<14:36,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\57070.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\57070.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 430/981 [10:09<13:05,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\93306.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\93306.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 431/981 [10:10<11:57,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\165995.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\165995.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 485/981 [11:27<10:44,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\152145.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\152145.png'\n",
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\154634.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\154634.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 529/981 [12:31<09:57,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\186702.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\186702.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 594/981 [14:03<07:48,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\53941.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\53941.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 610/981 [14:27<10:26,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\195657.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\195657.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 650/981 [15:25<07:16,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\128913.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\128913.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 692/981 [16:27<06:39,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка при открытии C:\\Users\\vds\\Work\\Programming Stuff\\ecup\\data\\images\\test\\7415.png: [Errno 2] No such file or directory: 'C:\\\\Users\\\\vds\\\\Work\\\\Programming Stuff\\\\ecup\\\\data\\\\images\\\\test\\\\7415.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 981/981 [22:47<00:00,  1.39s/it]\n"
     ]
    }
   ],
   "source": [
    "test_img_emb = compute_image_embeddings(df_test, TEST_DIR, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1278c3",
   "metadata": {},
   "source": [
    "Сохранение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93897e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_emb.to_parquet(DATA_DIR / \"train_clip_img_emb.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe8c3903",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_emb.to_parquet(DATA_DIR / \"test_clip_img_emb.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac302b1",
   "metadata": {},
   "source": [
    "Загрузка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76ace953",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_emb = pd.read_parquet(DATA_DIR / \"train_clip_img_emb.parquet\")\n",
    "test_img_emb = pd.read_parquet(DATA_DIR / \"test_clip_img_emb.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64b6632",
   "metadata": {},
   "source": [
    "## 2) Считывание текста с изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b60c6330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.1% Complete"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "\n",
    "# Инициализация OCR (английский + русский)\n",
    "ocr = easyocr.Reader(['en', 'ru'], gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "debec115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texts(df, img_dir):\n",
    "    texts, has_text = [], []\n",
    "    nan_count = 0\n",
    "    \n",
    "    for img_id in tqdm(df[\"ItemID\"]):\n",
    "        path = img_dir / f\"{img_id}.png\"\n",
    "        try:\n",
    "            result = ocr.readtext(str(path), detail=1)  # detail=1 → вернёт bbox, текст и уверенность\n",
    "            if result:\n",
    "                # Собираем все найденные строки\n",
    "                text_parts = [line[1] for line in result]  \n",
    "                text = \" \".join(text_parts)\n",
    "                texts.append(text)\n",
    "                has_text.append(1)\n",
    "            else:\n",
    "                texts.append(\"\")\n",
    "                has_text.append(0)\n",
    "        except Exception as e:\n",
    "            nan_count += 1\n",
    "            texts.append(\"\")\n",
    "            has_text.append(0)\n",
    "\n",
    "    print(f\"Преобразование выполнено, нет изображений у {nan_count} товаров из {len(df)} ({nan_count/len(df):.2%})\")\n",
    "    return texts, has_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3119e299",
   "metadata": {},
   "source": [
    "Применение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfac71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 655/197198 [09:54<49:32:01,  1.10it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_train[\u001b[33m\"\u001b[39m\u001b[33mocr_text\u001b[39m\u001b[33m\"\u001b[39m], df_train[\u001b[33m\"\u001b[39m\u001b[33mhas_text\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mextract_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTRAIN_DIR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m df_test[\u001b[33m\"\u001b[39m\u001b[33mocr_text\u001b[39m\u001b[33m\"\u001b[39m], df_test[\u001b[33m\"\u001b[39m\u001b[33mhas_text\u001b[39m\u001b[33m\"\u001b[39m] = extract_texts(df_test, TEST_DIR)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mextract_texts\u001b[39m\u001b[34m(df, img_dir)\u001b[39m\n\u001b[32m      6\u001b[39m path = img_dir / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.png\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     result = \u001b[43mocr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadtext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetail\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# detail=1 → вернёт bbox, текст и уверенность\u001b[39;00m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m     10\u001b[39m         \u001b[38;5;66;03m# Собираем все найденные строки\u001b[39;00m\n\u001b[32m     11\u001b[39m         text_parts = [line[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m result]  \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vds\\Work\\Programming Stuff\\ecup\\.venv\\Lib\\site-packages\\easyocr\\easyocr.py:456\u001b[39m, in \u001b[36mReader.readtext\u001b[39m\u001b[34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[39m\n\u001b[32m    450\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    451\u001b[39m \u001b[33;03mParameters:\u001b[39;00m\n\u001b[32m    452\u001b[39m \u001b[33;03mimage: file path or numpy-array or a byte stream object\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[33;03m'''\u001b[39;00m\n\u001b[32m    454\u001b[39m img, img_cv_grey = reformat_input(image)\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m horizontal_list, free_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mslope_ths\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mslope_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mycenter_ths\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mycenter_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mheight_ths\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth_ths\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth_ths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43madd_margin\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_margin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreformat\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m                                         \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[38;5;66;03m# get the 1st result from hor & free list as self.detect returns a list of depth 3\u001b[39;00m\n\u001b[32m    467\u001b[39m horizontal_list, free_list = horizontal_list[\u001b[32m0\u001b[39m], free_list[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vds\\Work\\Programming Stuff\\ecup\\.venv\\Lib\\site-packages\\easyocr\\easyocr.py:321\u001b[39m, in \u001b[36mReader.detect\u001b[39m\u001b[34m(self, img, min_size, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, add_margin, reformat, optimal_num_chars, threshold, bbox_min_score, bbox_min_size, max_candidates)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reformat:\n\u001b[32m    319\u001b[39m     img, img_cv_grey = reformat_input(img)\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m text_box_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_textbox\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m                            \u001b[49m\u001b[43moptimal_num_chars\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimal_num_chars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_min_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_min_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m                            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m horizontal_list_agg, free_list_agg = [], []\n\u001b[32m    338\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text_box \u001b[38;5;129;01min\u001b[39;00m text_box_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vds\\Work\\Programming Stuff\\ecup\\.venv\\Lib\\site-packages\\easyocr\\detection.py:95\u001b[39m, in \u001b[36mget_textbox\u001b[39m\u001b[34m(detector, image, canvas_size, mag_ratio, text_threshold, link_threshold, low_text, poly, device, optimal_num_chars, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m result = []\n\u001b[32m     94\u001b[39m estimate_num_chars = optimal_num_chars \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m bboxes_list, polys_list = \u001b[43mtest_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmag_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mlink_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimate_num_chars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimate_num_chars:\n\u001b[32m    100\u001b[39m     polys_list = [[p \u001b[38;5;28;01mfor\u001b[39;00m p, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(polys, key=\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mabs\u001b[39m(optimal_num_chars - x[\u001b[32m1\u001b[39m]))]\n\u001b[32m    101\u001b[39m                   \u001b[38;5;28;01mfor\u001b[39;00m polys \u001b[38;5;129;01min\u001b[39;00m polys_list]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vds\\Work\\Programming Stuff\\ecup\\.venv\\Lib\\site-packages\\easyocr\\detection.py:51\u001b[39m, in \u001b[36mtest_net\u001b[39m\u001b[34m(canvas_size, mag_ratio, net, image, text_threshold, link_threshold, low_text, poly, device, estimate_num_chars)\u001b[39m\n\u001b[32m     48\u001b[39m boxes_list, polys_list = [], []\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m y:\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# make score and link map\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     score_text = \u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.data.numpy()\n\u001b[32m     52\u001b[39m     score_link = out[:, :, \u001b[32m1\u001b[39m].cpu().data.numpy()\n\u001b[32m     54\u001b[39m     \u001b[38;5;66;03m# Post-processing\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "df_test[\"ocr_text\"], df_test[\"has_text\"] = extract_texts(df_test, TEST_DIR)\n",
    "df_train[\"ocr_text\"], df_train[\"has_text\"] = extract_texts(df_train, TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраним обновлённые таблицы\n",
    "os.makedirs(\"ocr\", exist_ok=True)\n",
    "\n",
    "df_train.to_csv(\"ocr/train_with_ocr.csv\", index=True)\n",
    "df_test.to_csv(\"ocr/test_with_ocr.csv\", index=True)\n",
    "\n",
    "print(\"OCR завершён, данные сохранены.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9c24fb",
   "metadata": {},
   "source": [
    "# Обучение модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e65bee5",
   "metadata": {},
   "source": [
    "### 1) Уменьшим размерность векторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ba091603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_vectors = PCA(n_components=142, random_state=34)\n",
    "\n",
    "train_img_emb_r = pca_vectors.fit_transform(train_img_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2f2b69",
   "metadata": {},
   "source": [
    "### 2) Получим векторы текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1c0a1a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, embeddings_test = data_preprocess.load_text_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9746994",
   "metadata": {},
   "source": [
    "### 3) Подготовим данные для модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4faf8714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмем числовные данные\n",
    "num_data = df_train_num.drop(columns=['resolution']).values\n",
    "\n",
    "# Также возьмем категориальные признаки\n",
    "cat_cols = [\"brand_name\", \"CommercialTypeName4\"]\n",
    "cat_data = df_train_text[cat_cols].astype(str)\n",
    "\n",
    "# Теперь объединяем: эмбеддинги + изображения + числовые\n",
    "X_num = np.concatenate([embeddings, train_img_emb_r, num_data], axis=1)  # (N, D + num_features)\n",
    "\n",
    "# Целевая переменная\n",
    "y = df_train_num[\"resolution\"].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e8cb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Трейн/тест сплит\n",
    "X_train_num, X_val_num, y_train, y_val, train_cat, val_cat = train_test_split(\n",
    "    X_num, y, cat_data, test_size=0.2, stratify=y, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5741e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Объединяем все в один датафрейм\n",
    "X_train = pd.concat(\n",
    "    [pd.DataFrame(X_train_num), train_cat.reset_index(drop=True)], axis=1\n",
    ")\n",
    "X_val = pd.concat(\n",
    "    [pd.DataFrame(X_val_num), val_cat.reset_index(drop=True)], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "098251db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Создаем пулы для catboost\n",
    "\n",
    "# Категориальные признаки теперь — последние len(cat_cols) колонок\n",
    "cat_features_idx = list(range(X_train_num.shape[1], X_train_num.shape[1] + len(cat_cols)))\n",
    "\n",
    "train_pool = Pool(X_train, label=y_train, cat_features=cat_features_idx)\n",
    "val_pool = Pool(X_val, label=y_val, cat_features=cat_features_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192e901c",
   "metadata": {},
   "source": [
    "### 4) Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f1fd8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CatBoostClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Модель\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mCatBoostClassifier\u001b[49m(\n\u001b[32m      3\u001b[39m     iterations=\u001b[32m500\u001b[39m,\n\u001b[32m      4\u001b[39m     depth=\u001b[32m11\u001b[39m,\n\u001b[32m      5\u001b[39m     learning_rate=\u001b[32m0.05\u001b[39m,\n\u001b[32m      6\u001b[39m     eval_metric=\u001b[33m\"\u001b[39m\u001b[33mF1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     random_seed=\u001b[32m42\u001b[39m,\n\u001b[32m      8\u001b[39m     od_type=\u001b[33m\"\u001b[39m\u001b[33mIter\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m      9\u001b[39m     od_wait=\u001b[32m50\u001b[39m,\n\u001b[32m     10\u001b[39m     task_type=\u001b[33m\"\u001b[39m\u001b[33mGPU\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCPU\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m model.fit(train_pool, eval_set=val_pool,\n\u001b[32m     14\u001b[39m     verbose=\u001b[32m100\u001b[39m,\n\u001b[32m     15\u001b[39m     use_best_model=\u001b[38;5;28;01mTrue\u001b[39;00m,      \u001b[38;5;66;03m# Использовать лучшую модель по валидации\u001b[39;00m\n\u001b[32m     16\u001b[39m     plot=\u001b[38;5;28;01mTrue\u001b[39;00m                 \u001b[38;5;66;03m# Построить график обучения\u001b[39;00m\n\u001b[32m     17\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'CatBoostClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "# Модель\n",
    "model = CatBoostClassifier(\n",
    "    iterations=500,\n",
    "    depth=11,\n",
    "    learning_rate=0.05,\n",
    "    eval_metric=\"F1\",\n",
    "    random_seed=42,\n",
    "    od_type=\"Iter\", \n",
    "    od_wait=50,\n",
    "    task_type=\"GPU\" if torch.cuda.is_available() else \"CPU\"\n",
    ")\n",
    "\n",
    "model.fit(train_pool, eval_set=val_pool,\n",
    "    verbose=100,\n",
    "    use_best_model=True,      # Использовать лучшую модель по валидации\n",
    "    plot=True                 # Построить график обучения\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8d6d47ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Classification report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9836    0.9904    0.9870     36830\n",
      "           1     0.8505    0.7674    0.8068      2610\n",
      "\n",
      "    accuracy                         0.9757     39440\n",
      "   macro avg     0.9171    0.8789    0.8969     39440\n",
      "weighted avg     0.9748    0.9757    0.9751     39440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Предсказания\n",
    "y_pred = model.predict(val_pool)\n",
    "print(\"\\n=== Classification report ===\")\n",
    "print(classification_report(y_val, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5a30e9",
   "metadata": {},
   "source": [
    "### 5) Получение ответов на тесте."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c478eed0",
   "metadata": {},
   "source": [
    "Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "380f3140",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_emb_r = pca_vectors.transform(test_img_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd095c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмем числовные данные\n",
    "num_data_test = df_test_num.values\n",
    "\n",
    "# Также возьмем категориальные признаки\n",
    "cat_cols = [\"brand_name\", \"CommercialTypeName4\"]\n",
    "cat_data_test = df_test_text[cat_cols].astype(str)\n",
    "\n",
    "# Теперь объединяем: эмбеддинги + числовые\n",
    "X_test_num = np.concatenate([embeddings_test, test_img_emb_r, num_data_test], axis=1)  # (N, D + num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "198e805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединяем в датафрейм для CatBoost\n",
    "X_test = pd.concat([pd.DataFrame(X_test_num), cat_data_test.reset_index(drop=True)], axis=1)\n",
    "\n",
    "test_pool = Pool(X_test, cat_features=cat_features_idx)  # cat_features_idx те же, что для валидации\n",
    "\n",
    "y_pred_test = model.predict(test_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af34b32",
   "metadata": {},
   "source": [
    "Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f96f665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создан файл submission.csv с 22760 предсказаниями\n",
      "Распределение предсказаний:\n",
      "prediction\n",
      "0    21442\n",
      "1     1318\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(test_pool)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': df_test.index,\n",
    "    'prediction': test_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "\n",
    "print(f\"Создан файл submission.csv с {len(submission)} предсказаниями\")\n",
    "print(f\"Распределение предсказаний:\")\n",
    "print(submission['prediction'].value_counts())\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
